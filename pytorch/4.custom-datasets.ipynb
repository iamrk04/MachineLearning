{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Datasets\n",
    "\n",
    "Format of the input: **[batch_size, no_of_channels, height, width]**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU information\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from scripts.utils import plot_predictions, plot_train_test_loss, print_train_time, eval_model_classification\n",
    "from pathlib import Path\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get data ready (turn into tensor)\n",
    "Our dataset is a subset of the Food101 dataset. Food101 starts 101 different classes of food and 1000 images per class (750 training, 250 testing). Our dataset starts with 3 classes of food and only 10% of the images (~75 training, 25 testing).\n",
    "\n",
    "Why do this?\n",
    "- When starting out ML projects, it's important to try things on a small scale and then increase the scale when necessary.\n",
    "- The whole point is to speed up how fast you can experiment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import zipfile\n",
    "from pathlib import Path\n",
    "\n",
    "# Setup path to a data folder\n",
    "data_path = Path(\"data/\")\n",
    "image_path = data_path / \"pizza_steak_sushi\"\n",
    "\n",
    "# If the image folder doesn't exist, download it and prepare it...\n",
    "if image_path.is_dir():\n",
    "  print(f\"{image_path} directory already exists... skipping download\")\n",
    "else:\n",
    "  print(f\"{image_path} does not exist, creating one...\")\n",
    "  image_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "  # Download pizza, steak and suhsi data\n",
    "  with open(data_path / \"pizza_steak_sushi.zip\", \"wb\") as f:\n",
    "    request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi.zip\")\n",
    "    print(\"Downloading pizza, steak, suhsi data...\")\n",
    "    f.write(request.content)\n",
    "\n",
    "  # Unzip pizza, steak, sushi data\n",
    "  with zipfile.ZipFile(data_path / \"pizza_steak_sushi.zip\", \"r\") as zip_ref:\n",
    "    print(\"Unzipping pizza, steak and sushi data...\")\n",
    "    zip_ref.extractall(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check details about data\n",
    "\n",
    "import os\n",
    "def walk_through_dir(dir_path):\n",
    "    \"\"\"Walks through dir_path returning its contents.\"\"\"\n",
    "    for dirpath, dirnames, filenames in os.walk(dir_path):\n",
    "        print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'.\")\n",
    "\n",
    "walk_through_dir(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup train and testing paths\n",
    "train_dir = image_path / \"train\"\n",
    "test_dir = image_path / \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data (randomly take some images)\n",
    "\n",
    "import random \n",
    "from PIL import Image\n",
    "\n",
    "# Set seed\n",
    "# random.seed(RANDOM_SEED)\n",
    "\n",
    "# 1. Get all image paths \n",
    "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
    "\n",
    "# 2. Pick a random image path\n",
    "random_image_path = random.choice(image_path_list)\n",
    "\n",
    "# 3. Get image class from path name (the image class is the name of the directory where the image is stored)\n",
    "image_class = random_image_path.parent.stem\n",
    "\n",
    "# 4. Open image\n",
    "img = Image.open(random_image_path)\n",
    "\n",
    "# 5. Print metadata \n",
    "print(f\"Random image path: {random_image_path}\")\n",
    "print(f\"Image class: {image_class}\")\n",
    "print(f\"Image height: {img.height}\")\n",
    "print(f\"Image width: {img.width}\")\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Turn the image into an array\n",
    "img_as_array = np.asarray(img)\n",
    "\n",
    "# Plot the image with matplotlib\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.imshow(img_as_array)\n",
    "plt.title(f\"Image class: {image_class} | Image shape: {img_as_array.shape} -> [height, width, color_channels] (HWC)\")\n",
    "plt.axis(False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Transform the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "# Write a transform for image\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.Resize(size=(64, 64)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.ToTensor() \n",
    "])\n",
    "\n",
    "print(f\"Shape of image before transform: {img_as_array.shape}\")\n",
    "print(f\"Shape of image after transform: {data_transform(img).shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_transformed_images(image_paths: list, transform, n=3, seed=None):\n",
    "  \"\"\"\n",
    "  Selects random images from a path of images and loads/transforms \n",
    "  them then plots the original vs the transformed version.\n",
    "  \"\"\"\n",
    "  if seed:\n",
    "    random.seed(seed)\n",
    "  random_image_paths = random.sample(image_paths, k=n)\n",
    "  for image_path in random_image_paths:\n",
    "    with Image.open(image_path) as f:\n",
    "      fig, ax = plt.subplots(nrows=1, ncols=2)\n",
    "      ax[0].imshow(f)\n",
    "      ax[0].set_title(f\"Original\\nSize: {f.size}\")\n",
    "      ax[0].axis(False)\n",
    "\n",
    "      # Transform and plot target image\n",
    "      transformed_image = transform(f).permute(1, 2, 0) # note we will need to change shape for matplotlib (C, H, W) -> (H, W, C)\n",
    "      ax[1].imshow(transformed_image)\n",
    "      ax[1].set_title(f\"Transformed\\nShape: {transformed_image.shape}\")\n",
    "      ax[1].axis(\"off\")\n",
    "\n",
    "      fig.suptitle(f\"Class: {image_path.parent.stem}\", fontsize=16)\n",
    "\n",
    "plot_transformed_images(image_paths=image_path_list,\n",
    "                        transform=data_transform,\n",
    "                        n=3,\n",
    "                        seed=None)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Convert data to pytorch dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.1 Convert to pytorch dataset using inbuilt `ImageFolder` within datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ImageFolder to create dataset(s)\n",
    "from torchvision import datasets\n",
    "\n",
    "train_data = datasets.ImageFolder(\n",
    "    root=train_dir,\n",
    "    transform=data_transform, # a transform for the data\n",
    "    target_transform=None # a transform for the label/target \n",
    ")\n",
    "\n",
    "test_data = datasets.ImageFolder(\n",
    "    root=test_dir,\n",
    "    transform=data_transform)\n",
    "\n",
    "train_data, test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get class names as list\n",
    "class_names = train_data.classes\n",
    "class_names\n",
    "\n",
    "# Get class names as dict\n",
    "class_dict = train_data.class_to_idx\n",
    "class_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index on the train_data Dataset to get a single image and label\n",
    "img, label = train_data[0][0], train_data[0][1]\n",
    "print(f\"Image tensor:\\n {img}\")\n",
    "print(f\"Image shape: {img.shape}\")\n",
    "print(f\"Image datatype: {img.dtype}\")\n",
    "print(f\"Image label: {label}\")\n",
    "print(f\"Label datatype: {type(label)}\")\n",
    "print(f\"Train data length: {len(train_data)}\")\n",
    "print(f\"Test data length: {len(test_data)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3.2 Convert to pytorch dataset with Custom `Dataset`\n",
    "\n",
    "1. Want to be able to load images from file\n",
    "2. Want to be able to get class names from the Dataset\n",
    "3. Want to be able to get classes as dictionary from the Dataset\n",
    "\n",
    "Pros:\n",
    "- Can create a `Dataset` out of almost anything\n",
    "- Not limited to PyTorch pre-built `Dataset` functions\n",
    "\n",
    "Cons:\n",
    "- Even though you could create `Dataset` out of almost anything, it doesn't mean it will work.\n",
    "- Using a custom `Dataset` often results in us writing more code, which could be prone to errors or performance issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pathlib\n",
    "import torch\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "from typing import Tuple, Dict, List\n",
    "\n",
    "\n",
    "def find_classes(directory: str) -> Tuple[List[str], Dict[str, int]]:\n",
    "    \"\"\"Finds the class folder names in a target directory.\"\"\"\n",
    "    # 1. Get the class names by scanning the target directory\n",
    "    classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
    "\n",
    "    # 2. Raise an error if class names could not be found\n",
    "    if not classes:\n",
    "        raise FileNotFoundError(f\"Couldn't find any classes in {directory}... please check file structure.\")\n",
    "\n",
    "    # 3. Create a dictionary of index labels (computers prefer numbers rather than strings as labels)\n",
    "    class_to_idx = {class_name: i for i, class_name in enumerate(classes)}\n",
    "    return classes, class_to_idx\n",
    "\n",
    "find_classes(train_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Write a custom dataset class\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "# 1. Subclass torch.utils.data.Dataset\n",
    "class ImageFolderCustom(Dataset):\n",
    "    # 2. Initialize our custom dataset\n",
    "    def __init__(self, targ_dir: str, transform=None):\n",
    "        # 3. Create class attributes\n",
    "        # Get all of the image paths\n",
    "        self.paths = list(pathlib.Path(targ_dir).glob(\"*/*.jpg\"))\n",
    "        # Setup transform\n",
    "        self.transform = transform\n",
    "        # Create classes and class_to_idx attributes\n",
    "        self.classes, self.class_to_idx = find_classes(targ_dir)\n",
    "\n",
    "    # 4. Create a function to load images\n",
    "    def load_image(self, index: int) -> Image.Image:\n",
    "        \"Opens an image via a path and returns it.\"\n",
    "        image_path = self.paths[index]\n",
    "        return Image.open(image_path)\n",
    "\n",
    "    # 5. Overwrite __len__()\n",
    "    def __len__(self) -> int:\n",
    "        \"Returns the total number of samples.\"\n",
    "        return len(self.paths)\n",
    "\n",
    "    # 6. Overwrite __getitem__() method to return a particular sample\n",
    "    def __getitem__(self, index: int) -> Tuple[torch.Tensor, int]:\n",
    "        \"Returns one sample of data, data and label (X, y).\"\n",
    "        img = self.load_image(index)\n",
    "        class_name = self.paths[index].parent.name # expects path in format: data_folder/class_name/image.jpg\n",
    "        class_idx = self.class_to_idx[class_name]\n",
    "\n",
    "        # Transform if necessary\n",
    "        if self.transform:\n",
    "            return self.transform(img), class_idx # return data, label (X, y)\n",
    "        else:\n",
    "            return img, class_idx # return untransformed image and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test out ImageFolderCustom\n",
    "import pandas as pd\n",
    "\n",
    "train_data_custom = ImageFolderCustom(targ_dir=train_dir, transform=transforms)\n",
    "test_data_custom = ImageFolderCustom(targ_dir=test_dir, transform=transforms)\n",
    "\n",
    "compare = pd.DataFrame(\n",
    "    {\n",
    "        \"Train Data\": [len(train_data), train_data.classes, train_data.class_to_idx],\n",
    "        \"Train Data Custom\": [len(train_data_custom), train_data_custom.classes, train_data_custom.class_to_idx],\n",
    "        \"Test Data\": [len(test_data), test_data.classes, test_data.class_to_idx],\n",
    "        \"Test Data Custom\": [len(test_data_custom), test_data_custom.classes, test_data_custom.class_to_idx]\n",
    "    },\n",
    "    index=[\"Length\", \"Classes\", \"Class to Index Dict\"]\n",
    ")\n",
    "compare"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Prepare DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=os.cpu_count()\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=os.cpu_count()\n",
    ")\n",
    "\n",
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize one sample from train_dataloader\n",
    "import numpy as np\n",
    "\n",
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "print(f\"train_features_batch: {train_features_batch.shape}\")\n",
    "print(f\"train_labels_batch: {train_labels_batch.shape}\")\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "rand_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
    "img, label = train_features_batch[rand_idx], train_labels_batch[rand_idx]\n",
    "\n",
    "img_as_array = np.asarray(img.permute(1, 2, 0))\n",
    "plt.imshow(img_as_array)\n",
    "plt.title(f\"{label}: {class_names[label]}\")\n",
    "plt.axis(False)\n",
    "print(f\"Image size: {img.shape}\")\n",
    "print(f\"Label size: {label.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Data Augmentation\n",
    "- Data augmentation is the process of artificially adding diversity to your training data.\n",
    "- In the case of image data, this may mean applying various image transformations to the training images.\n",
    "- This practice hopefully results in a model that's more generalizable to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let's look at trivailaugment - https://pytorch.org/vision/stable/auto_examples/plot_transforms.html#trivialaugmentwide \n",
    "from torchvision import transforms\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=(224, 224)),\n",
    "        transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=(224, 224)),\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Plot random transformed images\n",
    "plot_transformed_images(\n",
    "    image_paths=image_path_list,\n",
    "    transform=train_transform,\n",
    "    n=3,\n",
    "    seed=None\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build or pick a pretrained model for training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When starting to build a series of machine learning modelling experiments, it's best practice to start with a baseline model. A baseline model is a simple model you will try and improve upon with subsequent models/experiments. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.0 Build a model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.0.1 Creating transforms and loading data for Model 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create simple transform\n",
    "simple_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=(64, 64)),\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# 1. Load and transform data\n",
    "from torchvision import datasets\n",
    "\n",
    "train_data_simple = datasets.ImageFolder(root=train_dir, transform=simple_transform)\n",
    "test_data_simple = datasets.ImageFolder(root=test_dir, transform=simple_transform)\n",
    "\n",
    "# 2. Turn the datasets into DataLoaders\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Setup batch size and number of works\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "# Create DataLoader's\n",
    "train_dataloader_simple = DataLoader(\n",
    "    dataset=train_data_simple,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True, \n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "test_dataloader_simple = DataLoader(\n",
    "    dataset=test_data_simple,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.0.2 Create TinyVGG model class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Explained: https://poloclub.github.io/cnn-explainer/\n",
    "class TinyVGG(nn.Module):\n",
    "    \"\"\"\n",
    "    Model architecture copying TinyVGG from CNN Explainer: https://poloclub.github.io/cnn-explainer/\n",
    "    \"\"\"\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # trick to calculate in_features - use print in forward function before using this layer\n",
    "            # pass in one tensor to see the shape and then calculate\n",
    "            nn.Linear(in_features=hidden_units * 13 * 13, out_features=output_shape)\n",
    "        ).to(device=DEVICE)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # X = self.conv_block_1(X)\n",
    "        # X = self.conv_block_2(X)\n",
    "        # # print(X.shape)          # this will help to find out `in_features` for the classifier layer\n",
    "        # X = self.classifier(X)\n",
    "        # return X\n",
    "        return self.classifier(self.conv_block_2(self.conv_block_1(X)))\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "model_0 = TinyVGG(input_shape=3, hidden_units=10, output_shape=len(class_names))\n",
    "model_0.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if model is correctly built\n",
    "\n",
    "# dummy_x = torch.rand([1, 3, 64, 64])\n",
    "# model_0(dummy_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.0.3 Summary of model using torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model_0, input_size=[1, 3, 64, 64])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Pick loss function and optimizer\n",
    "We will do this in the next section."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Build a training loop to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "from scripts.utils import train, plot_loss_curves\n",
    "\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "\n",
    "EPOCHS = 10\n",
    "\n",
    "# Recreate an instance of TinyVGG\n",
    "model_0 = TinyVGG(input_shape=3, hidden_units=30, output_shape=len(train_data.classes)).to(DEVICE)\n",
    "\n",
    "# Setup loss function and optimizer \n",
    "loss_fn = nn.CrossEntropyLoss() \n",
    "optimizer = torch.optim.Adam(params=model_0.parameters(), lr=0.001)\n",
    "\n",
    "start_timer = timer()\n",
    "model_0_res = train(\n",
    "    model=model_0,\n",
    "    train_dataloader=train_dataloader_simple,\n",
    "    test_dataloader=test_dataloader_simple,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    epochs=EPOCHS,\n",
    "    device=DEVICE\n",
    ")\n",
    "end_timer = timer()\n",
    "train_time_0 = print_train_time(start_timer, end_timer, DEVICE)\n",
    "\n",
    "print(model_0_res)\n",
    "plot_loss_curves(model_0_res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model_0_res = eval_model_classification(\n",
    "    model=model_0,\n",
    "    data_loader=test_dataloader_simple,\n",
    "    loss_fn=loss_fn,\n",
    "    accuracy_fn=accuracy_score\n",
    ")\n",
    "print(model_0_res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Improve through experimentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Build new model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.1 Creating transforms and loading data for Model 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training transform with TriviailAugment\n",
    "from torchvision import transforms\n",
    "\n",
    "train_transform_trivial = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=(64, 64)),\n",
    "        transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transform_simple = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=(64, 64)),\n",
    "        transforms.ToTensor()\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Turn image folders into Datasets\n",
    "from torchvision import datasets\n",
    "\n",
    "train_data_augmented = datasets.ImageFolder(root=train_dir, transform=train_transform_trivial)\n",
    "test_data_simple = datasets.ImageFolder(root=test_dir, transform=test_transform_simple)\n",
    "\n",
    "# Turn our Datasets into DataLoaders\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = os.cpu_count()\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "train_dataloader_augmented = DataLoader(\n",
    "    dataset=train_data_augmented,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS\n",
    ")\n",
    "\n",
    "test_dataloader_simple = DataLoader(\n",
    "    dataset=test_data_simple,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False,\n",
    "    num_workers=NUM_WORKERS\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2 Create new model\n",
    "We will use the same TinyVGG model class."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Pick loss function and optimizer\n",
    "We will do this in the next section."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Build training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "from scripts.utils import train, plot_loss_curves\n",
    "\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "torch.cuda.manual_seed(RANDOM_SEED)\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "# Recreate an instance of TinyVGG\n",
    "model_1 = TinyVGG(input_shape=3, hidden_units=10, output_shape=len(train_data_augmented.classes))\n",
    "model_1 = model_1.to(DEVICE)\n",
    "\n",
    "# Setup loss function and optimizer \n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(params=model_1.parameters(), lr=0.001)\n",
    "\n",
    "start_timer = timer()\n",
    "model_1_res = train(\n",
    "    model=model_1,\n",
    "    train_dataloader=train_dataloader_augmented,\n",
    "    test_dataloader=test_dataloader_simple,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    epochs=EPOCHS,\n",
    "    device=DEVICE\n",
    ")\n",
    "end_timer = timer()\n",
    "train_time_1 = print_train_time(start_timer, end_timer, DEVICE)\n",
    "\n",
    "print(model_1_res)\n",
    "plot_loss_curves(model_1_res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Evaluate the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For model_1\n",
    "\n",
    "model_1_res = eval_model_classification(\n",
    "    model=model_1,\n",
    "    data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    accuracy_fn=accuracy_score\n",
    ")\n",
    "model_1_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all models\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "all_result = pd.DataFrame([\n",
    "    model_0_res,\n",
    "    model_1_res,\n",
    "])\n",
    "all_result[\"training_time\"] = [train_time_0, train_time_1]\n",
    "all_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the result\n",
    "all_result.set_index(\"model_name\")[\"model_accuracy\"].plot(kind=\"barh\")\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize random predictions\n",
    "from scripts.utils import make_predictions\n",
    "\n",
    "# random.seed(RANDOM_SEED)\n",
    "y_preds = make_predictions(model_0, test_dataloader_simple)\n",
    "\n",
    "rows, cols = 3, 3\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "for i in range(1, rows * cols + 1):\n",
    "  rand_idx = torch.randint(0, len(test_data), size=[1]).item()\n",
    "  X, y_truth = test_data_simple[rand_idx]\n",
    "  y_truth = class_names[y_truth]\n",
    "  y_pred = class_names[y_preds[rand_idx]]\n",
    "  fig.add_subplot(rows, cols, i)\n",
    "  img_as_array = np.asarray(X.permute(1, 2, 0))\n",
    "  plt.imshow(img_as_array)\n",
    "  if y_pred == y_truth:\n",
    "    plt.title(f\"Truth: {y_truth} | Pred: {y_pred}\", c=\"g\")\n",
    "  else:\n",
    "    plt.title(f\"Truth: {y_truth} | Pred: {y_pred}\", c=\"r\")\n",
    "  plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils import make_predictions\n",
    "\n",
    "\n",
    "# Make predictions with trained model\n",
    "y_pred_tensor = make_predictions(model_0, test_dataloader_simple, DEVICE)\n",
    "y_pred_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import ConfusionMatrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "# 2. Setup confusion instance and compare predictions to targets\n",
    "confmat = ConfusionMatrix(task='multiclass', num_classes=len(class_names))\n",
    "confmat_tensor = confmat(preds=y_pred_tensor,\n",
    "                         target=torch.tensor(test_data_simple.targets))\n",
    "\n",
    "# 3. Plot the confusion matrix\n",
    "fig, ax = plot_confusion_matrix(\n",
    "    conf_mat=confmat_tensor.numpy(), # matplotlib likes working with numpy\n",
    "    class_names=class_names,\n",
    "    figsize=(10, 7)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save and reload trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "\n",
    "model_folder = Path(\"models\")\n",
    "model_folder.mkdir(parents=True, exist_ok=True)\n",
    "model_name = \"FoodSmall101_VGG.pt\"\n",
    "model_path = model_folder / model_name\n",
    "\n",
    "model_0.to(device=DEVICE)\n",
    "torch.save(obj=model_0.state_dict(), f=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "\n",
    "loaded_model = TinyVGG(input_shape=3, hidden_units=30, output_shape=len(class_names))\n",
    "loaded_model.load_state_dict(torch.load(f=model_path))\n",
    "loaded_model.to(device=DEVICE)\n",
    "# loaded_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate loaded model\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "loaded_model_0_results = eval_model_classification(\n",
    "    model=loaded_model,\n",
    "    data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    accuracy_fn=accuracy_score\n",
    ")\n",
    "\n",
    "loaded_model_0_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if model results are close to each other\n",
    "torch.isclose(torch.tensor(model_0_res[\"model_loss\"]),\n",
    "              torch.tensor(loaded_model_0_results[\"model_loss\"]),\n",
    "              atol=1e-02)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Making prediciton on a custom image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download custom image\n",
    "import requests\n",
    "\n",
    "# Setup custom image path\n",
    "custom_image_path = data_path / \"04-pizza-dad.jpeg\"\n",
    "\n",
    "# Download the image if it doesn't already exist\n",
    "if not custom_image_path.is_file():\n",
    "  with open(custom_image_path, \"wb\") as f:\n",
    "    # When downloading from GitHub, need to use the \"raw\" file link\n",
    "    request = requests.get(\"https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/images/04-pizza-dad.jpeg\")\n",
    "    print(f\"Downloading {custom_image_path}...\")\n",
    "    f.write(request.content)\n",
    "else:\n",
    "  print(f\"{custom_image_path} already exists, skipping download...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create transform pipeline to resize image\n",
    "from torchvision import transforms\n",
    "\n",
    "custom_image_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.Resize(size=(64, 64))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils import pred_and_plot_single_image\n",
    "\n",
    "# Pred on our custom image\n",
    "pred_and_plot_single_image(\n",
    "    model=model_0,\n",
    "    image_path=custom_image_path,\n",
    "    class_names=class_names,\n",
    "    transform=custom_image_transform,\n",
    "    device=DEVICE\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vision\n",
    "\n",
    "Format of the input: **[batch_size, no_of_channels, height, width]**\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU information\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from scripts.utils import plot_predictions, plot_train_test_loss, print_train_time, eval_model_classification\n",
    "from pathlib import Path\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "RANDOM_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(torch.__version__)\n",
    "print(torchvision.__version__)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Get data ready (turn into tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the data\n",
    "\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None\n",
    ")\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    "    target_transform=None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check details about data\n",
    "\n",
    "class_names = train_data.classes\n",
    "print(class_names)\n",
    "print(train_data.class_to_idx)\n",
    "print()\n",
    "\n",
    "image, label = train_data[0]\n",
    "print(f\"Image shape: {image.shape} -> [color_channels, height, width]\")      # [color_channels, height, width]\n",
    "print(f\"Image label: {class_names[label]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the data (randomly take some images)\n",
    "\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "train_data_len = len(train_data)\n",
    "rows, cols = 4, 4\n",
    "for i in range(1, rows * cols + 1):\n",
    "    rand_idx = torch.randint(0, train_data_len, size=[1]).item()\n",
    "    image, label = train_data[rand_idx]\n",
    "    fig.add_subplot(rows, cols, i)\n",
    "    plt.imshow(image.squeeze(), cmap=\"gray\")\n",
    "    plt.title(f\"{label}: {train_data.classes[label]}\")\n",
    "    plt.axis(False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Prepare DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    dataset=train_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    dataset=test_data,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize one sample from train_dataloader\n",
    "\n",
    "train_features_batch, train_labels_batch = next(iter(train_dataloader))\n",
    "print(f\"train_features_batch: {train_features_batch.shape}\")\n",
    "print(f\"train_labels_batch: {train_labels_batch.shape}\")\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "rand_idx = torch.randint(0, len(train_features_batch), size=[1]).item()\n",
    "img, label = train_features_batch[rand_idx], train_labels_batch[rand_idx]\n",
    "\n",
    "plt.imshow(img.squeeze(), cmap=\"gray\")\n",
    "plt.title(f\"{label}: {class_names[label]}\")\n",
    "plt.axis(False)\n",
    "print(f\"Image size: {img.shape}\")\n",
    "print(f\"Label size: {label.shape}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Build or pick a pretrained model for training"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When starting to build a series of machine learning modelling experiments, it's best practice to start with a baseline model. A baseline model is a simple model you will try and improve upon with subsequent models/experiments. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMnistModelV0(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.layer_stack = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
    "            # nn.Softmax(dim=1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.layer_stack(X)\n",
    "\n",
    "\n",
    "model_0 = FashionMnistModelV0(input_shape=28*28, hidden_units=10, output_shape=len(class_names))\n",
    "model_0.to(DEVICE)\n",
    "model_0.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if model is correctly built\n",
    "\n",
    "dummy_x = torch.rand([1, 1, 28, 28])\n",
    "model_0(dummy_x)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Pick loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(params=model_0.parameters(), lr=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Build a training loop to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from timeit import default_timer as timer\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "EPOCHS = 3\n",
    "epoch_count = []\n",
    "train_loss_arr = []\n",
    "test_loss_arr = []\n",
    "test_acc_arr = []\n",
    "\n",
    "start_timer = timer()\n",
    "\n",
    "for epoch in tqdm(range(EPOCHS)):\n",
    "    print(f\"Epoch: {epoch}\\n----------\")\n",
    "\n",
    "    # train\n",
    "    train_loss = 0\n",
    "    model_0.train()\n",
    "    for batch, (X, y) in enumerate(train_dataloader):\n",
    "        y_logit = model_0(X)\n",
    "        y_prob = torch.softmax(y_logit, dim=1)\n",
    "        y_pred = y_prob.argmax(dim=1)\n",
    "        loss = loss_fn(y_logit, y)\n",
    "        train_loss += loss\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print out what's happening\n",
    "        if batch % 400 == 0:\n",
    "            print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples.\")\n",
    "    train_loss /= len(train_dataloader)\n",
    "\n",
    "    # test\n",
    "    test_loss, test_acc = 0, 0\n",
    "    model_0.eval()\n",
    "    with torch.inference_mode():\n",
    "        for batch, (X, y) in enumerate(test_dataloader):\n",
    "            y_logit = model_0(X)\n",
    "            y_prob = torch.softmax(y_logit, dim=1)\n",
    "            y_pred = y_prob.argmax(dim=1)\n",
    "            test_loss += loss_fn(y_logit, y)\n",
    "            test_acc += accuracy_score(y.cpu().numpy(), y_pred.cpu().numpy())\n",
    "        test_loss /= len(test_dataloader)\n",
    "        test_acc /= len(test_dataloader)\n",
    "\n",
    "    epoch_count.append(epoch)\n",
    "    train_loss_arr.append(train_loss)\n",
    "    test_loss_arr.append(test_loss)\n",
    "    test_acc_arr.append(test_acc)\n",
    "\n",
    "end_timer = timer()\n",
    "train_time_0 = print_train_time(start_timer, end_timer, DEVICE)\n",
    "\n",
    "plot_train_test_loss(epoch_count, train_loss_arr, test_loss_arr)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Make prediction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_0_res = eval_model_classification(\n",
    "    model=model_0,\n",
    "    data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    accuracy_fn=accuracy_score\n",
    ")\n",
    "print(model_0_res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Improve through experimentation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Build new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMnistModelV1(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(in_features=input_shape, out_features=hidden_units),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=hidden_units, out_features=output_shape),\n",
    "            # nn.Softmax(dim=1)\n",
    "        ).to(device=DEVICE)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.model(X)\n",
    "\n",
    "\n",
    "# CNN Explained: https://poloclub.github.io/cnn-explainer/\n",
    "class FashionMnistModelV2(nn.Module):\n",
    "    def __init__(self, input_shape: int, hidden_units: int, output_shape: int):\n",
    "        super().__init__()\n",
    "        self.conv_block_1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.conv_block_2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2)\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            # trick to calculate in_features - use print in forward function before using this layer\n",
    "            # pass in one tensor to see the shape and then calculate\n",
    "            nn.Linear(in_features=hidden_units * 7 * 7, out_features=output_shape)\n",
    "        )\n",
    "\n",
    "    def forward(self, X):\n",
    "        X = self.conv_block_1(X)\n",
    "        X = self.conv_block_2(X)\n",
    "        # print(X.shape)          # this will help to find out `in_features` for the classifier layer\n",
    "        X = self.classifier(X)\n",
    "        return X\n",
    "\n",
    "model_1 = FashionMnistModelV1(input_shape=28*28, hidden_units=10, output_shape=len(class_names))\n",
    "model_1.to(DEVICE)\n",
    "# model_1.state_dict()\n",
    "\n",
    "# input_shape now refers to the number of color channels in CNN\n",
    "model_2 = FashionMnistModelV2(input_shape=1, hidden_units=10, output_shape=len(class_names))\n",
    "model_2.to(DEVICE)\n",
    "# model_2.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this cell wil fail, but the printed shape is going to help us decide `in_features` for the classifier layer\n",
    "# rand_tensor = torch.randn(*train_data[0][0].size())\n",
    "# model_2(rand_tensor)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Pick loss function and optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = torch.optim.SGD(params=model_1.parameters(), lr=0.1)\n",
    "optimizer_2 = torch.optim.SGD(params=model_2.parameters(), lr=0.1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3 Build training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For model_1\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from scripts.utils import train, plot_loss_curves\n",
    "\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "EPOCHS = 3\n",
    "epoch_count = []\n",
    "train_loss_arr = []\n",
    "train_acc_arr = []\n",
    "test_loss_arr = []\n",
    "test_acc_arr = []\n",
    "\n",
    "start_timer = timer()\n",
    "model_1_res = train(\n",
    "    model=model_1,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer,\n",
    "    epochs=EPOCHS,\n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "end_timer = timer()\n",
    "train_time_1 = print_train_time(start_timer, end_timer, DEVICE)\n",
    "\n",
    "print(model_1_res)\n",
    "plot_loss_curves(model_1_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For model_2\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from scripts.utils import train, plot_loss_curves\n",
    "\n",
    "\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "EPOCHS = 3\n",
    "\n",
    "start_timer = timer()\n",
    "model_2_res = train(\n",
    "    model=model_2,\n",
    "    train_dataloader=train_dataloader,\n",
    "    test_dataloader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    optimizer=optimizer_2,\n",
    "    epochs=EPOCHS,\n",
    "    device=DEVICE\n",
    ")\n",
    "end_timer = timer()\n",
    "train_time_2 = print_train_time(start_timer, end_timer, DEVICE)\n",
    "\n",
    "print(model_2_res)\n",
    "plot_loss_curves(model_2_res)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.4 Evaluate the new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For model_1\n",
    "\n",
    "model_1_res = eval_model_classification(\n",
    "    model=model_1,\n",
    "    data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    accuracy_fn=accuracy_score\n",
    ")\n",
    "model_1_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For model_2\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model_2_res = eval_model_classification(\n",
    "    model=model_2,\n",
    "    data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    accuracy_fn=accuracy_score\n",
    ")\n",
    "model_2_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate all models\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "all_result = pd.DataFrame([\n",
    "    model_0_res,\n",
    "    model_1_res,\n",
    "    model_2_res\n",
    "])\n",
    "all_result[\"training_time\"] = [train_time_0, train_time_1, train_time_2]\n",
    "all_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the result\n",
    "all_result.set_index(\"model_name\")[\"model_accuracy\"].plot(kind=\"barh\")\n",
    "plt.xlabel(\"Accuracy\")\n",
    "plt.ylabel(\"Models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize random predictions\n",
    "from scripts.utils import make_predictions\n",
    "\n",
    "# random.seed(RANDOM_SEED)\n",
    "y_preds = make_predictions(model_2, test_dataloader)\n",
    "\n",
    "rows, cols = 3, 3\n",
    "fig = plt.figure(figsize=(9, 9))\n",
    "for i in range(1, rows * cols + 1):\n",
    "  rand_idx = torch.randint(0, len(test_data), size=[1]).item()\n",
    "  X, y_truth = test_data[rand_idx]\n",
    "  y_truth = class_names[y_truth]\n",
    "  y_pred = class_names[y_preds[rand_idx]]\n",
    "  fig.add_subplot(rows, cols, i)\n",
    "  plt.imshow(X.squeeze(), cmap=\"gray\")\n",
    "  if y_pred == y_truth:\n",
    "    plt.title(f\"Truth: {y_truth} | Pred: {y_pred}\", c=\"g\")\n",
    "  else:\n",
    "    plt.title(f\"Truth: {y_truth} | Pred: {y_pred}\", c=\"r\")\n",
    "  plt.axis(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.utils import make_predictions\n",
    "\n",
    "\n",
    "# Make predictions with trained model\n",
    "y_pred_tensor = make_predictions(model_2, test_dataloader, DEVICE)\n",
    "y_pred_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import ConfusionMatrix\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "# 2. Setup confusion instance and compare predictions to targets\n",
    "confmat = ConfusionMatrix(task='multiclass', num_classes=len(class_names))\n",
    "confmat_tensor = confmat(preds=y_pred_tensor,\n",
    "                         target=test_data.targets)\n",
    "\n",
    "# 3. Plot the confusion matrix\n",
    "fig, ax = plot_confusion_matrix(\n",
    "    conf_mat=confmat_tensor.numpy(), # matplotlib likes working with numpy\n",
    "    class_names=class_names,\n",
    "    figsize=(10, 7)\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save and reload trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_folder = Path(\"models\")\n",
    "model_folder.mkdir(parents=True, exist_ok=True)\n",
    "model_name = \"FashionMnistModelV2.pt\"\n",
    "model_path = model_folder / model_name\n",
    "\n",
    "model_2.to(device=DEVICE)\n",
    "torch.save(obj=model_2.state_dict(), f=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model\n",
    "loaded_model = FashionMnistModelV2(input_shape=1, hidden_units=10, output_shape=len(class_names))\n",
    "loaded_model.load_state_dict(torch.load(f=model_path))\n",
    "loaded_model.to(device=DEVICE)\n",
    "# loaded_model.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate loaded model\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "loaded_model_2_results = eval_model_classification(\n",
    "    model=loaded_model,\n",
    "    data_loader=test_dataloader,\n",
    "    loss_fn=loss_fn,\n",
    "    accuracy_fn=accuracy_score\n",
    ")\n",
    "\n",
    "loaded_model_2_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if model results are close to each other\n",
    "torch.isclose(torch.tensor(model_2_res[\"model_loss\"]),\n",
    "              torch.tensor(loaded_model_2_results[\"model_loss\"]),\n",
    "              atol=1e-02)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
